{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a788e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The spatial gene expression dataset available on 10x genomics wesbite provides following files: \n",
    "#(i) probe file with the description of probes and their target genes, \n",
    "#(ii) barcoded BAM file with the information of reads alignment,\n",
    "#(iii) feature-barcode matrices used for secondary analysis,\n",
    "#(iv) spatial imaging data that describes spot barcode locations in the tissue section images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96b961",
   "metadata": {},
   "source": [
    "## Process the SAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the BAM to SAM file\n",
    "#From the SAM file we need to keep only the reads belonging to in-tissue spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find out the list of spot barcodes that contain tissue:\n",
    "\n",
    "# Read the list of barcodes from \"barcodes.tsv\"\n",
    "barcodes_set = set()\n",
    "with open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FF_HBC/filtered_feature_bc_matrix/barcodes.tsv\", \"r\") as barcode_file:\n",
    "    for line in barcode_file:\n",
    "        barcode = line.strip()\n",
    "        barcodes_set.add(barcode)\n",
    "\n",
    "# Filter and write the matching lines to a new SAM file\n",
    "with open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FF_HBC/CytAssist_Fresh_all.sam\", \"r\") as sam_file, open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FF_HBC/CytAssist_Fresh_in_tissue.sam\", \"w\") as output_file:\n",
    "    for line in sam_file:\n",
    "        if \"CB:Z:\" in line:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            for field in fields:\n",
    "                if field.startswith(\"CB:Z:\"):\n",
    "                    barcode = field[5:]\n",
    "                    if barcode in barcodes_set:\n",
    "                        output_file.write(line)\n",
    "                        break  # No need to check further fields for this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c451c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To filter out the reads that donot belong to in-tissue spots:\n",
    "\n",
    "#Read the list of barcodes from \"barcodes.tsv\"\n",
    "barcodes_set = set()\n",
    "with open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/input_gene_data/barcodes.tsv\", \"r\") as barcode_file:\n",
    "    for line in barcode_file:\n",
    "        barcode = line.strip()\n",
    "        barcodes_set.add(barcode)\n",
    "\n",
    "# Filter and write the matching lines to a new SAM file\n",
    "with open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/CytAssist_FFPE_Human_Skin_Melanoma_possorted_genome_sam.sam\", \"r\") as sam_file, open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/CytAssist_FFPE_Melanoma_in_tissue.sam\", \"w\") as output_file:\n",
    "    for line in sam_file:\n",
    "        if \"CB:Z:\" in line:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            for field in fields:\n",
    "                if field.startswith(\"CB:Z:\"):\n",
    "                    barcode = field[5:]\n",
    "                    if barcode in barcodes_set:\n",
    "                        output_file.write(line)\n",
    "                        break  # No need to check further fields for this line\n",
    "\n",
    "#reads from all spots = 193483397\n",
    "#reads from in-tissue spots = 186179197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2640538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only reads that have MAPQ (mapping quality) 255 and SAM flag 0 or 16. Remove the rest.\n",
    "#Done on command line:\n",
    "#awk '$5 == 255 && ($2 == \"0\" || $2 == \"16\") {print}' CytAssist_FFPE_Melanoma_in_tissue.sam > CytAssist_FFPE_Melanoma_in_tissue_fr.sam\n",
    "#fr stands for filtered reads\n",
    "#After this filtering, 111411063 reads remain. (Initally, in tissue reads were 186179197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6176973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then keep only those reads targeted by TRUE, sp+unsp+misid probes (filtered probes)\n",
    "#The following code chunk is to remove the reads from FALSE, DEPRECATED probes.\n",
    "#For this we can use the file \"Exon/ALL_filt_probes_targeting_exons_col1\" (53219 probes)\n",
    "#this file is made by taking first column of the file \"ALL_filt_probes_targeting_exons\"\n",
    "#in this list we don't consider 249 filt true probes because they don't have target exons\n",
    "\n",
    "## Read probe IDs from the CSV file\n",
    "csv_probe_ids = set()\n",
    "with open('/work/FAC/FBM/DBC/cdessim2/default/amaurya/Exons/ALL_filt_probes_targeting_exons_col1', 'r') as csv_file:\n",
    "    next(csv_file)  # Skip the header row\n",
    "    for line in csv_file:\n",
    "        probe_id = line.strip()\n",
    "        csv_probe_ids.add(probe_id)\n",
    "\n",
    "# Open the SAM files for reading and writing\n",
    "with open('/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/CytAssist_FFPE_Melanoma_in_tissue_fr.sam', 'r') as input_file, open('/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/CytAssist_FFPE_Melanoma_in_tissue_016fr_trueprobe.sam', 'w') as output_file:\n",
    "    for line in input_file:\n",
    "        if line.startswith('@'):  # Preserve header lines\n",
    "            output_file.write(line)\n",
    "        else:\n",
    "            fields = line.split('\\t')\n",
    "            for field in fields:\n",
    "                if field.startswith('pr:Z:'):\n",
    "                    probe_id = field.split(':')[2]\n",
    "                    if probe_id in csv_probe_ids:\n",
    "                        output_file.write(line)\n",
    "                        break  # Found a matching probe ID, no need to check other fields\n",
    "\n",
    "# Close the files\n",
    "input_file.close()\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b62ac0",
   "metadata": {},
   "source": [
    "## Generate the probe count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20558f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After selecting the desired probes, create the probe count matrix\n",
    "#the following chunk counts the reads of each probe in each barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801e7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store probe_id counts for each spot_barcode\n",
    "matrix_data = {}\n",
    "\n",
    "# Path to SAM file\n",
    "with open('/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/CytAssist_FFPE_Melanoma_in_tissue_016fr_trueprobe.sam', 'r') as sam_file:\n",
    "    for line in sam_file:\n",
    "        fields = line.strip().split('\\t')\n",
    "        \n",
    "        # Extract probe_id and spot_barcode\n",
    "        probe_id = None\n",
    "        spot_barcode = None\n",
    "        for field in fields:\n",
    "            if field.startswith(\"pr:Z:\"):\n",
    "                probe_id = field.split(':')[2]\n",
    "            elif field.startswith(\"CB:Z:\"):\n",
    "                spot_barcode = field.split(':')[2]\n",
    "                break\n",
    "        \n",
    "        # Update the matrix_data dictionary\n",
    "        if probe_id and spot_barcode:\n",
    "            if probe_id not in matrix_data:\n",
    "                matrix_data[probe_id] = {}\n",
    "            if spot_barcode not in matrix_data[probe_id]:\n",
    "                matrix_data[probe_id][spot_barcode] = 0\n",
    "            matrix_data[probe_id][spot_barcode] += 1\n",
    "\n",
    "# Extract unique spot_barcodes and probe_ids\n",
    "unique_spot_barcodes = sorted(set(barcode for data in matrix_data.values() for barcode in data.keys()))\n",
    "unique_probe_ids = sorted(matrix_data.keys())\n",
    "\n",
    "# Create the matrix\n",
    "matrix = []\n",
    "for probe_id in unique_probe_ids:\n",
    "    row = [matrix_data[probe_id].get(barcode, 0) for barcode in unique_spot_barcodes]\n",
    "    matrix.append(row)\n",
    "    \n",
    "# Save the matrix to a file\n",
    "output_file_path = '/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/probe_count_matrix'\n",
    "with open(output_file_path, 'w') as matrix_file:\n",
    "    # Write the header (spot_barcodes)\n",
    "    matrix_file.write(\"\\t\" + \"\\t\".join(unique_spot_barcodes) + \"\\n\")\n",
    "\n",
    "    # Write the matrix data\n",
    "    for probe_id, row in zip(unique_probe_ids, matrix):\n",
    "        matrix_file.write(probe_id + \"\\t\" + \"\\t\".join(map(str, row)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ef6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4677b87",
   "metadata": {},
   "source": [
    "## Create all chr exon matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df168e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, replace the probe_id by its matching exon_id (creating a new line for each exon_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following chunk replaces the probe_ids by corresponding exon_ids. \n",
    "#Two probe_ids may target same exon_ids so this chunk will replace the both probe with same exon_ids\n",
    "#Therefore, the ouput will contain duplicate lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ac406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read the probe-exon mapping file and create a dictionary\n",
    "probe_to_exon = {}\n",
    "with open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/Exons/ALL_filt_probes_targeting_exons\", \"r\") as mapping_file:\n",
    "    for line in mapping_file:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        probe_id = parts[0].strip().lower()  # Convert to lowercase and strip white spaces #this is imp\n",
    "        exon_ids = parts[1].split(\";\")\n",
    "        probe_to_exon[probe_id] = exon_ids\n",
    "\n",
    "# Step 2: Process the count matrix line by line\n",
    "with open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/probe_count_matrix\", \"r\") as count_matrix_file, open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/exon_count_matrix_with_dup\", \"w\", newline=\"\") as new_matrix_file:\n",
    "    count_matrix_reader = csv.reader(count_matrix_file, delimiter=\"\\t\")\n",
    "    new_matrix_writer = csv.writer(new_matrix_file, delimiter=\"\\t\")\n",
    "\n",
    "    for row in count_matrix_reader:\n",
    "        probe_id = row[0].strip().lower()  # Convert to lowercase and strip white spaces\n",
    "        counts = row[1:]\n",
    "        \n",
    "        if probe_id in probe_to_exon:\n",
    "            exon_ids = probe_to_exon[probe_id]\n",
    "            for exon_id in exon_ids:\n",
    "                new_matrix_writer.writerow([exon_id] + counts)\n",
    "        else:\n",
    "            new_matrix_writer.writerow([probe_id] + counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93938b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#the file \"exon_count_matrix_with_dup\" can be deleted later\n",
    "#sum up the counts of duplicate exon_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595c4b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged count matrix with summed counts has been saved to exon_count_matrix.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read the modified count matrix and create a dictionary to store counts for each unique exon ID\n",
    "exon_counts = {}\n",
    "\n",
    "with open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/exon_count_matrix_with_dup\", \"r\") as modified_matrix_file:\n",
    "    modified_matrix_reader = csv.reader(modified_matrix_file, delimiter=\"\\t\")\n",
    "    barcode_line = next(modified_matrix_reader)  # Store the barcode line\n",
    "\n",
    "    for row in modified_matrix_reader:\n",
    "        exon_id = row[0].strip()          #strip white spaces #IMPORTANT\n",
    "        counts = list(map(int, row[1:]))  #Convert counts to integers\n",
    "        if exon_id in exon_counts:\n",
    "            # If the exon ID is already in the dictionary, add the counts\n",
    "            exon_counts[exon_id] = [x + y for x, y in zip(exon_counts[exon_id], counts)]\n",
    "        else:\n",
    "            # If the exon ID is not in the dictionary, initialize it with the counts\n",
    "            exon_counts[exon_id] = counts\n",
    "\n",
    "# Step 2: Write the merged count matrix with summed counts, including the barcode line\n",
    "with open(\"/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/input_exon_data/exon_count_matrix\", \"w\", newline=\"\") as merged_matrix_file:\n",
    "    merged_matrix_writer = csv.writer(merged_matrix_file, delimiter=\"\\t\")\n",
    "    merged_matrix_writer.writerow(barcode_line)  # Write the barcode line\n",
    "\n",
    "    for exon_id, counts in exon_counts.items():\n",
    "        merged_matrix_writer.writerow([exon_id] + list(map(str, counts)))\n",
    "\n",
    "print(\"Merged count matrix with summed counts has been saved to exon_count_matrix.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94123e83",
   "metadata": {},
   "source": [
    "## Prepare STARCH input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c167635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing features.tsv for exons: (we need exons present in count matrix)\n",
    "# Extract the features (exon_ids) i.e the first field of all lines\n",
    "# cut -f 1 exon_count_matrix > f1.tsv\n",
    "# there might be an empty first line, check and delete if needed: sed -i 1d\n",
    "# Create a duplicate of this column →  awk -F'\\t' '{print $1 \"\\t\" $1}' f1.tsv > f2.tsv\n",
    "# Add a third field “Exon Expression” to each row → awk 'BEGIN {OFS=\"\\t\"} {$3=\"Exon Expression\"; print}' f2.tsv > features.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For preparing hgtable for exon matrix:\n",
    "# First print an empty line: echo “” > file.txt\n",
    "# Then add numbers starting from zero: for i in {0..261184}; do echo $i >> file.txt; done\n",
    "# (261184 is one less than total)\n",
    "# In exon id file add a header row: echo -e \"chrom\\tcdsStart\\tcdsEnd\\tname2\" > output.txt\n",
    "# cat unique_exon_ids_coordinates.txt >> output.txt\n",
    "# Merge the two files: paste file.txt output.txt > merged_output.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792ddd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e99c9eb",
   "metadata": {},
   "source": [
    "## Convert to matrix.mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c495d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a features.tsv file (a numbered list of exons in count matrix)\n",
    "#cut -f 1 exon_count_matrix > features1.tsv (use sed -i 1d if blank line at top)\n",
    "#awk 'BEGIN{OFS=\"\\t\"} {print NR, $0}' features1.tsv > features_with_serial.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7ff63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exon_ids = []  # List to store exon IDs\n",
    "barcode_ids = []  # List to store barcode IDs\n",
    "\n",
    "# Load exon IDs from the exon_id.tsv file\n",
    "with open('/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/input_exon_data/features_with_serial.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        exon_ids.append(line.strip())\n",
    "\n",
    "# Load barcode IDs from the barcode_id.tsv file\n",
    "with open('/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/input_exon_data/barcodes_with_serial.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        barcode_ids.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39fea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input matrix below should not have row and column headers. Just the counts.\n",
    "#Remove the first row: awk 'NR > 1' exon_count_matrix > new_matrix\n",
    "#Remove the first col: cut -f 2- < new_matrix > output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2f89ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = np.genfromtxt('/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/input_exon_data/output_matrix', delimiter='\\t', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5822f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_matrix = np.transpose(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142c8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Create a COO (Coordinate) matrix\n",
    "sparse_matrix = coo_matrix(transposed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4286f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy's mmwrite function to save the sparse matrix in Matrix Market format\n",
    "sio.mmwrite('/work/FAC/FBM/DBC/cdessim2/default/amaurya/CytAssist_FFPE_melanoma/input_exon_data/matrix_v1.mtx', sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The matrix_v1.mtx generated has the fields in incorrect order. So need to interchange the first and second field.\n",
    "# awk '{print $2, $1, $3}' matrix_v1.mtx > matrix.mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#However, the two headers of matrix.mtx generated here do not match the 10x output matrix.\n",
    "#So, need to modify the matrix.mtx headers\n",
    "# First, delete first header: sed -i '1d' matrix.mtx\n",
    "#Then add desired first header: sed -i '1s/^/%%MatrixMarket matrix coordinate integer general\\n/' matrix.mtx\n",
    "#Next, delete second header: sed -i '2d' matrix.mtx\n",
    "#Then add desired second header: sed -i '2s/^/%metadata_json: {\"software_version\": \"spaceranger-2.0.1\", \"format_version\": 2}\\n/' matrix.mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82dbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940eccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
